{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeoML with EuroSAT and TorchGeo\n",
    "Now that we know how to use Pytorch for machine learning, we're going to use a related library designed to work with geospatial data and models within PyTorch called [TorchGeo](https://github.com/microsoft/torchgeo). The documentation is [here](https://torchgeo.readthedocs.io/en/latest/) and the associated publication from 2021 [here](https://arxiv.org/abs/2111.08872). It is an active community and well maintained repository that is super useful especially for pulling in existing models and working with satellite imagery and geospatial datasets. \n",
    "\n",
    "\n",
    "In this notebook, we'll be using a benchmark dataset called \"EuroSAT\" that includes 27,000 satellite image patches from Sentinel-2 over Europe along with a label about what the image is of. This is a more complex dataset, and so we'll need a deeper neural network to classify the images. We'll create a commonly-used type of convolutional neural network (CNN) used for image classifcation, [ResNet](https://arxiv.org/abs/1512.03385), and compare the performance of randomly initialized weights versus pretrained weights.\n",
    "\n",
    "**Learning Outcomes**:\n",
    "- Learn the basics of the TorchGeo API\n",
    "- Learn an API for working with satellite imagery\n",
    "- Train a Convolutional Neural Network for image classification\n",
    "- Learn to pull pretrained weights for a model and compare performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Before we start, we'll definitely want to use GPUs for this task since the dataset and the neural network are much larger than we were using before. A ResNet18 has about 11 million parameters and the EuroSAT dataset has about 2GB of data. This pales compared to 1.76 trillion parameters in GPT-4 (about 10^5 times smaller), but we're not OpenAI, everyone starts somewhere.\n",
    "\n",
    "We'll mostly be training in this notebook, so go ahead and use the higher power P100 GPU. I encourage you to play around with the GPUs and see what difference they make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# install torchgeo\n",
    "%pip install torchgeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "print(\"no more files\")\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# data libraries\n",
    "from torch.utils.data import DataLoader\n",
    "from torchgeo.datasets import EuroSAT\n",
    "import random\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ml libraries\n",
    "import torch # for model training\n",
    "from torch import nn # for neural network layers\n",
    "from torch.utils.data import RandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2 as transforms\n",
    "\n",
    "print(\"import complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Visualize EuroSat Data\n",
    "\n",
    "We'll be classiying the EuroSAT dataset from [this 2017 paper](https://arxiv.org/abs/1709.00029). The images are from the [Sentinel-2 satellite constellation](https://www.esa.int/Applications/Observing_the_Earth/Copernicus/Sentinel-2) from the European Space Agency. It takes multi-spectral (visible light plus some longer wavelengths) images of all land on Earth every 5 days at 30-meter spatial resolution.\n",
    "\n",
    "Instead of downloading the dataset to our computers then uploading to Kaggle, we will use the `torchgeo` API to pull in the dataset. It will download a `.zip` will all of the images, and then 3 `.txt` files that contain a list of the filenames of each images for training, validation, and test data. This is standard for datasets in `torchgeo`. This also means that the images won't get loaded in memory until we actually need them, hooray for efficiency!\n",
    "\n",
    "In this next section, we use the torchgeo dataset/datamodules to download the EuroSat dataset. We also calculate the number of samples in each split and visualize an image or two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "eurosat_root = os.path.join(\"data\", \"eurosat\")\n",
    "eurosat_dataset_train = EuroSAT(eurosat_root, split=\"train\", download=True)\n",
    "eurosat_dataset_val = EuroSAT(eurosat_root, split=\"val\", download=True)\n",
    "eurosat_dataset_test = EuroSAT(eurosat_root, split=\"test\", download=True)\n",
    "\n",
    "print(f'Dataset Classes: {eurosat_dataset_train.classes}')\n",
    "print(f'Number of images in train dataset: {len(eurosat_dataset_train)}')\n",
    "print(f'Number of images in val dataset: {len(eurosat_dataset_val)}')\n",
    "print(f'Number of images in test dataset: {len(eurosat_dataset_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # of Images in Each Dataset Split\n",
    "Split    | %            | EuroSAT   |\n",
    "---------|-----------   |---------  |\n",
    "Train    |  60          |   16200   |\n",
    "Validate |  20          |   5400    |\n",
    "Test     |  20          |   5400    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# visualize just one image\n",
    "fig = eurosat_dataset_train.plot(\n",
    "    sample=eurosat_dataset_train.__getitem__(1),\n",
    "    show_titles=True\n",
    ")\n",
    "\n",
    "# modify this code to inspect a few different images and get a sense of the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Evaluate a Model on the EuroSAT Data \n",
    "\n",
    "In this section, we train two ResNet models on the nonspatial EuroSat dataset: one with randomly initialized weights, and one with pre-initialized weights from the SSL4EO-S12 project (use the pretrained weights available in torchgeo).\n",
    "\n",
    "The flow of this section is as follows:\n",
    "1. Configure the GPU\n",
    "1. Define the train and test loops\n",
    "1. Define a ResNet model with random weights, customize the model for EuroSat data\n",
    "1. Define a data sampler and loader\n",
    "1. Load and transform the data\n",
    "1. Train & evaluate the model\n",
    "1. Repeat with a pre-trained ResNet\n",
    "1. Report results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure GPU\n",
    "\n",
    "This should output `cuda` if you activated the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "torch.manual_seed(44)\n",
    "\n",
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure CPU for Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# see how many processes can be run on the CPU\n",
    "import multiprocessing\n",
    "pool = multiprocessing.Pool()\n",
    "pool._processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Train & Test Loops\n",
    "\n",
    "These are pulled from the pytorch getting started tutorial. I've added a comment to every single line to explain what the code is doing to help demystify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the training loop function\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    # Get the total number of samples in the dataset\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Loop through batches of data provided by the dataloader\n",
    "    for batch, sample in enumerate(dataloader):\n",
    "        # Extract input data (images) and corresponding labels from the batch\n",
    "        X, y = sample['image'], sample['label']\n",
    "        # Move the input data and labels to the specified device (e.g., GPU or CPU)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # Forward pass: Compute the model's predictions for the inputs\n",
    "        pred = model(X)\n",
    "        # Compute the loss between predictions and true labels\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation: Compute gradients of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # Update model parameters using the optimizer\n",
    "        optimizer.step()\n",
    "        # Reset gradients to zero to prevent accumulation\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # print another period after each batch to track progress\n",
    "        print('.', end='', flush=True)\n",
    "\n",
    "print(\"train loop defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the testing or validation loop function\n",
    "def test(dataloader, model, loss_fn, val=False):\n",
    "    # Get the total number of samples in the dataset\n",
    "    size = len(dataloader.dataset)\n",
    "    # Get the total number of batches in the dataloader\n",
    "    num_batches = len(dataloader)\n",
    "    # Set the model to evaluation mode (disables dropout and other training-specific layers)\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize variables to accumulate total loss and correct predictions\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    # Disable gradient calculations for efficiency during testing/validation\n",
    "    with torch.no_grad():\n",
    "        # Loop through batches of data provided by the dataloader\n",
    "        for sample in dataloader:\n",
    "            # Extract input data (images) and corresponding labels from the batch\n",
    "            X, y = sample['image'], sample['label']\n",
    "            # Move the input data and labels to the specified device (e.g., GPU or CPU)\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # Forward pass: Compute the model's predictions for the inputs\n",
    "            pred = model(X)\n",
    "            # Compute the loss for this batch and add it to the total loss\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            # Count the number of correct predictions (highest logit matches the label)\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    # Compute the average loss over all batches\n",
    "    test_loss /= num_batches\n",
    "    # Compute the overall accuracy as the fraction of correct predictions\n",
    "    correct /= size\n",
    "    \n",
    "    # Determine whether this is a validation or test loop and adjust the output prefix\n",
    "    prefix = \"Validation\" if val else \"Test\"\n",
    "    # Print the accuracy and average loss\n",
    "    print(f\"\\n{prefix} Error: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
    "\n",
    "print(\"test loop defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Data Transforms\n",
    "\n",
    "The EuroSAT images are 64x64 pixels, but ResNet50 typically uses 224x224 inputs, as standardized by the [ImageNet dataset](https://www.image-net.org/). To deal with this, let's resize the images using a Pytorch transform before the are run through the model. We'll need to define a custom transform class to handle the torchgeo dataset format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# custom transform function to handle the dictionary structure of torchgeo dataset\n",
    "class CustomTransform:\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sample['image'] = self.transform(sample['image'])\n",
    "        return sample\n",
    "    \n",
    "# Define transformations for the dataset to get it from 64x64 to 224x224\n",
    "transform = transforms.Resize((224, 224))  # Resizes the images to 224x224\n",
    "\n",
    "custom_transform = CustomTransform(transform)\n",
    "\n",
    "print(\"data transform defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Dataloaders\n",
    "\n",
    "Just like last week, we need to create datasets and dataloaders within Pytorch so that our model knows how to iterate over data when training. We'll also tell the dataloaders how many CPU cores we have to maximize data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_eurosat_data(txs, batch_size):\n",
    "    # reload data with the new transform\n",
    "    root = os.path.join(\"data\", \"eurosat\")\n",
    "    dataset_train = EuroSAT(root, split=\"train\", download=True, transforms=txs)\n",
    "    dataset_val = EuroSAT(root, split=\"val\", download=True, transforms=txs)\n",
    "    dataset_test = EuroSAT(root, split=\"test\", download=True, transforms=txs)\n",
    "\n",
    "    # define a sampler for the EuroSAT dataset\n",
    "    # it's a non-spatial dataset, so we can use a regular sampler from pytorch\n",
    "    sampler_train = RandomSampler(dataset_train, replacement=False) # start with a small batch\n",
    "    sampler_val = RandomSampler(dataset_val, replacement=False) # start with a small batch\n",
    "    sampler_test = RandomSampler(dataset_test, replacement=False) # start with a small batch\n",
    "\n",
    "    # define a dataloader to iterate over the dataset\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=batch_size, sampler=sampler_train, num_workers=4)\n",
    "    dataloader_val = DataLoader(dataset_val, batch_size=batch_size, sampler=sampler_val, num_workers=4)\n",
    "    dataloader_test = DataLoader(dataset_test, batch_size=batch_size, sampler=sampler_test, num_workers=4)\n",
    "    \n",
    "    return dataloader_train, dataloader_val, dataloader_test\n",
    "\n",
    "print(\"dataloader defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Train, Val, Test Function\n",
    "Instead of calling training, validation, and testing functions for each loop, let's define a standard train/val/test function to wrap them. In this loop, we \"baseline\" the test and validation data before and after training to see how we're improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_val_test(dataloader_train, dataloader_val, dataloader_test, model, loss_fn=nn.CrossEntropyLoss(), lr=1e-3, epochs=5):\n",
    "    # record the start time to analyze GPU efficiency\n",
    "    start_time = datetime.datetime.now() \n",
    "    print(f\"Training started at\", start_time)\n",
    "    \n",
    "    # create optimizer from the model and the learning rate\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # print hyperparameters\n",
    "    print(\"Hyperparameters -- Batch Size:\",batch_size,\"Learning Rate:\",lr,\"Epochs:\",epochs)\n",
    "    \n",
    "    # baseline performance on the test data before training\n",
    "    print(f\"Calculate Baseline Performance on Test Data Before Training...\\n-------------------------------\")\n",
    "    test(dataloader_test, model, loss_fn, val=False)\n",
    "\n",
    "    # run train / val loop\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        epoch_start_time = datetime.datetime.now()\n",
    "        print(f\"Epoch started at\", epoch_start_time)\n",
    "        train(dataloader_train, model, loss_fn, optimizer)\n",
    "        test(dataloader_val, model, loss_fn, val=True)\n",
    "        epoch_end_time = datetime.datetime.now()\n",
    "        epoch_duration = epoch_end_time - epoch_start_time\n",
    "        print(f\"Epoch training and validation lasted for\", epoch_duration)\n",
    "\n",
    "    # test result with test data\n",
    "    print(\"Test Results\\n-------------------------------\")\n",
    "    test(dataloader_test, model, loss_fn, val=False)\n",
    "\n",
    "    end_time = datetime.datetime.now()\n",
    "    train_duration = end_time - start_time\n",
    "    print(\"Training completed in\", train_duration, \"!\")\n",
    "\n",
    "def evaluate_model(model, dataloader_test, loss_fn=nn.CrossEntropyLoss()):\n",
    "    print(f\"Evaluating Model on Test Data\\n-------------------------------\")\n",
    "    test(dataloader_test, model, loss_fn, val=False)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a Function to Save Down the Model\n",
    "We'll output to the kaggle working directory in a subfolder called models. Each time we run a model, we should name our \"experiment\" so we remember what hyperparameters we were using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_model(model, experiment_name):\n",
    "    if not os.path.exists(\"models\"):\n",
    "        os.makedirs(\"models\")\n",
    "    model_weights_path = os.path.join(\"models\", experiment_name)\n",
    "    torch.save(model.state_dict(), model_weights_path)\n",
    "    print(\"Model saved to\", model_weights_path)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Model\n",
    "\n",
    "`torchgeo` has a nifty API for pulling in some standard models, like ResNet50. Let's import the model along with the pre-trained weights that are available for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchgeo.models import resnet18 # import resnet model from torchvision\n",
    "from torchgeo.models import ResNet18_Weights # import pre-trained model weights for resnet\n",
    "from torchsummary import summary # for viewing a condensed model\n",
    "\n",
    "print(\"imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# pull in a resnet\n",
    "# use randomly initialized weights\n",
    "# modify the ResNet model to have 13 input channels (instead of the standard 3 for RGB)\n",
    "# modify the ResNet model to have 10 output classes (instead of the standard 1000 for ImageNet)\n",
    "model = resnet18(weights=None, in_chans=13, num_classes=10).to(device)\n",
    "\n",
    "# summarize the model for the given input size \n",
    "# image input size is (num_channels, width, height)\n",
    "input_size = (13, 224, 224)\n",
    "summary(model, input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the EuroSAT Data\n",
    "Use the function we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "dataloader_train, dataloader_val, dataloader_test = load_eurosat_data(custom_transform, batch_size=batch_size)\n",
    "print(\"data loaded into memory\")\n",
    "print(\"using batch size\", batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train & Test the Model\n",
    "Run the train, validate, and test loop we defined earlier. Each \".\" printed represents one batch run through the model, the loss calculated, and the gradient calculated, and the parameters updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "lr = 1e-4\n",
    "train_val_test(dataloader_train, dataloader_val, dataloader_test, model, lr=lr, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the Current Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "save_model(model, \"eurosat_resnet18_bs64_lr0001_epochs1.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recreate Model with Pre-Trained Weights\n",
    "Some research has looked into using unlabeled data to \"pre-train\" models to be more prepared for downstream tasks. Here's we'll use a pretrained model from a group of researchers at the Technical University of Munich (TUM) who pretrained a model by aligning Sentinel-1 SAR imagery with Sentinel-2 multispectral imagery. Learn more about the dataset on their [Github](https://github.com/zhu-xlab/SSL4EO-S12), with the paper on [arXiv](https://arxiv.org/abs/2211.07044), or in the [torchgeo documentation](https://torchgeo.readthedocs.io/en/stable/_modules/torchgeo/models/resnet.html#ResNet18_Weights). TorchGeo makes it possible to preload our resnet with these pretrained weights in a single line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# this version already expects 13 input channels\n",
    "# set it to predict 10 classes\n",
    "# pull in the pretrained weights from SSL4EO-S12 MoCo \n",
    "pretrained_model = resnet18(weights=ResNet18_Weights.SENTINEL2_ALL_MOCO, in_chans=13, num_classes=10).to(device)\n",
    "\n",
    "# view the model again\n",
    "summary(pretrained_model, input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train & Test the Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_val_test(dataloader_train, dataloader_val, dataloader_test, pretrained_model, lr=1e-3, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Down the Fine-Tuned Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "save_model(model, \"eurosat_resnet18_pretrained_bs64_lr001_epochs1.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Given Model\n",
    "If you have a model saved that you would like to train further, use the code below to load the weights so that you can evaluate it or continue training. If you continue training, I suggest using the same hyperparameters that you used to train that model in the first place, just run it for more epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_model(experiment_name):\n",
    "    # create an empty res net with the right io dimensions\n",
    "    model = resnet18(weights=None, in_chans=13, num_classes=10).to(device)\n",
    "    # create the path to the model weights\n",
    "    model_weights_path = os.path.join(\"models\", experiment_name)\n",
    "    # load the model weights from the path\n",
    "    model.load_state_dict(torch.load(model_weights_path, weights_only=True))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "experiment_name = \"eurosat_resnet18_bs64_lr001_epochs1.pth\"\n",
    "model = load_model(experiment_name)\n",
    "print(\"model loaded and ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "1. **Maximize Training Efficiency**: Before trying to train your best model for many epochs, try out different batch sizes (ie. 16, 32, 64, 128, 256, 512, etc), number of workers (ie. 0,1,2,4,8), and which GPU (ie GPU P100, T4x2) for training just 1 epoch. See which configuration is able to train an epoch the fastest. You should be able to get it under two minutes for a single epoch. Take note of CPU and GPU usage in the top right dashboard as training happens. Record what the most efficient configuration is and use that for the next part. Write down what you're trying and what the results are.\n",
    "\n",
    "2. **Maximize Accuracy**: Now mess with the hyperparameters to see what combination leads to the highest accuracy. Namely, experiment with the number of epochs, the learning rate, and if you're feeling curious, potentially even the optimizer and the loss function to achieve the best accuracy. Report your results in a table like this one. Compare your results to the results reported in the original [EuroSAT paper from 2017](https://arxiv.org/abs/1709.00029) and the [SSL4EO-S12 paper from 2022](https://arxiv.org/abs/2211.07044).\n",
    "\n",
    "|   Dataset |   Img Tx         | Model         |LR   | BS | Epochs | Accuracy  |\n",
    "|-----------|------------------|---------------|-----|----|--------|-----------|\n",
    "|   EuroSAT | Resize           | ResNet18      |0.001| 64 | 1      | 74.8%     |\n",
    "|   EuroSAT | Resize           | ResNet18      |0.001| 128| 5      | 87.6%     |\n",
    "|   EuroSAT | Resize           | ResNet18 MoCo |0.001| 64 | 10     | 97.6%     |\n",
    "|   EuroSAT | Resize           | ResNet18 MoCo |0.001| 256| 20     | 74.4%     |\n",
    "|   EuroSAT | Resize           | ResNet50      |0.001| 64 | 30     | 86.2%     |\n",
    "|   EuroSAT | Resize           | ResNet50      |0.001| 512| 50     | 91.8%     |\n",
    "|   EuroSAT | Resize & Flip VH | ResNet50 MoCo |0.001| 32 | 5      | 60.4%     |\n",
    "|   EuroSAT | Resize & Flip VH | ResNet50 MoCo |0.001| 64 | 10     | 95.7%     |\n",
    "\n",
    "3. **Reflection Question**: What applications could a highly accurate land cover classification model be used for that relate to the [UN's 17 Sustainable Development Goals](https://sdgs.un.org/goals)? Write out your answer.\n",
    "\n",
    "## Bonus Challenge #1: Plotting Loss per Epoch\n",
    "A common practice in ML is to report your loss over time as you train and validate your model with each epoch. For this challenge, implement code that records the training and validation loss after each epoch and then plot it. \n",
    "\n",
    "## Bonus Challenge #2: F1 Score\n",
    "The [F1 score](https://www.geeksforgeeks.org/f1-score-in-machine-learning/) is a more nuanced metric than accuracy that focusses on precision and recall. Implement the reporting of the F1 score of your model alongside the accuracy when evaluating the model on validation or test data.\n",
    "\n",
    "## Bonus Challenge #3: Using a TPU\n",
    "Do whatever code adaptations are necessary to run this code on the TPU VM v3-8 available in Kaggle. Track the changes you make, and then report on how this affects training speed. \n",
    "\n",
    "## Bonus Challenge #4: Adding Data Augmentation\n",
    "The code below adds in some data augmentations before running the data through the model. This is a technique that is often used to get the most out of your training data and ensure that the representations learned by the model are as general as possible. For this challenge, use the code below as a guide to add data augmentations to the training pipeline. Feel free to use whatever data augmentations you'd like, just provide a justification as to why you used those. Compare how this affects your accuracy on the validation and test data. Reflect on why you are seeing the results you are. Below is a code chunk that should help you as a starting point:\n",
    "```{python}\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Randomly flip the image horizontally\n",
    "    transforms.RandomVerticalFlip(p=0.5),  # Randomly flip the image vertically\n",
    "    transforms.Resize((224, 224))  # Resizes the images to 224x224\n",
    "])\n",
    "\n",
    "custom_transform = CustomTransform(transform)\n",
    "```\n",
    "\n",
    "## Deliverables\n",
    "1. Submit the Kaggle URL of your notebook with the cells run to the Discord channel #notebook-submissions. Make sure you've clicked \"Save Version\" and ensure that the notebook is public before submitting it.\n",
    "2. Find an accountability buddy for your Python learning, and do the first lesson of the course. Post in the #python-learning channel when you have a buddy and when you've completed the first lesson.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
