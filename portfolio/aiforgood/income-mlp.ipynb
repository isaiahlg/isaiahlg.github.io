{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to MLPs using US Census Income Data\n",
    "\n",
    "I developed this notebook for Week 3 of a course, AI for Good, that I co-teach with [Professor Zia Mehrabi](https://www.colorado.edu/envs/zia-mehrabi). In this notebook, we'll use a simple MLP to predict whether an individual makes over or under $50,000 per year based on some demographic characteristics. This notebook was created largely from [this one](https://www.kaggle.com/code/dogukantabak/income-prediction-pytorch). The dataset we'll use is on Kaggle [here](https://www.kaggle.com/datasets/jainaru/adult-income-census-dataset/data).  \n",
    "\n",
    "Learning outcomes:\n",
    "1. Pull in data on Kaggle\n",
    "2. Inspect and explore the data\n",
    "3. Split the dataset into train/test\n",
    "4. Train classical machine learning models on the data\n",
    "5. Build and train simple ANN with Pytorch for classification\n",
    "\n",
    "<img src=\"https://isaiahlg.com/portfolio/csci5922/mod2/nn1.png\" alt=\"Basic MLP\" style=\"width:37%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income Predictor Dataset - US Adult\n",
    "Link: https://www.kaggle.com/datasets/jainaru/adult-income-census-dataset/data\n",
    "\n",
    "The Adult Census Income dataset, extracted from the 1994 US Census Database by Barry Becker, serves as a valuable resource for understanding the intricate interplay between socio-economic factors and income levels. Comprising anonymized information such as occupation, age, native country, race, capital gain, capital loss, education, work class, and more, this dataset offers a comprehensive view of the American demographic landscape.\n",
    "\n",
    "**Dataset Overview**\n",
    "The dataset consists of two CSV files: adult-training.txt and adult-test.txt, each row representing an individual. Key features include occupation, age, native country, race, capital gain, capital loss, education, work class, and more. The target variable, 'income_bracket', categorizes individuals into two groups: \">50K\" and \"<=50K\".\n",
    "\n",
    "**Exploration and Preprocessing**\n",
    "Exploring the dataset reveals a mix of categorical and continuous features, as well as missing values. Understanding the distribution and relationships of these features is crucial for feature selection and data preprocessing, including handling missing values and encoding categorical variables.\n",
    "\n",
    "**Modeling and Evaluation**\n",
    "To predict income levels, various classifiers can be trained on the training dataset and evaluated using the test dataset. Algorithms such as logistic regression, decision trees, random forests, and neural networks can be employed based on the dataset's complexity and the desired performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>?</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt     education  education.num marital.status  \\\n",
       "0   90         ?   77053       HS-grad              9        Widowed   \n",
       "1   82   Private  132870       HS-grad              9        Widowed   \n",
       "2   66         ?  186061  Some-college             10        Widowed   \n",
       "3   54   Private  140359       7th-8th              4       Divorced   \n",
       "4   41   Private  264663  Some-college             10      Separated   \n",
       "\n",
       "          occupation   relationship   race     sex  capital.gain  \\\n",
       "0                  ?  Not-in-family  White  Female             0   \n",
       "1    Exec-managerial  Not-in-family  White  Female             0   \n",
       "2                  ?      Unmarried  Black  Female             0   \n",
       "3  Machine-op-inspct      Unmarried  White  Female             0   \n",
       "4     Prof-specialty      Own-child  White  Female             0   \n",
       "\n",
       "   capital.loss  hours.per.week native.country income  \n",
       "0          4356              40  United-States  <=50K  \n",
       "1          4356              18  United-States  <=50K  \n",
       "2          4356              40  United-States  <=50K  \n",
       "3          3900              40  United-States  <=50K  \n",
       "4          3900              40  United-States  <=50K  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/adult.csv') # read in the file\n",
    "data.head() # look at the first few rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education.num   32561 non-null  int64 \n",
      " 5   marital.status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital.gain    32561 non-null  int64 \n",
      " 11  capital.loss    32561 non-null  int64 \n",
      " 12  hours.per.week  32561 non-null  int64 \n",
      " 13  native.country  32561 non-null  object\n",
      " 14  income          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info() # look at the various columns and their data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values by column:\n",
      " age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education.num     0\n",
      "marital.status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital.gain      0\n",
      "capital.loss      0\n",
      "hours.per.week    0\n",
      "native.country    0\n",
      "income            0\n",
      "dtype: int64\n",
      "Number of duplicate rows:  24\n"
     ]
    }
   ],
   "source": [
    "# look for null values and duplicate rows\n",
    "print(\"Null values by column:\\n\", data.isnull().sum())\n",
    "print(\"Number of duplicate rows: \", data.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 30139 entries, 1 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             30139 non-null  int64 \n",
      " 1   workclass       30139 non-null  object\n",
      " 2   fnlwgt          30139 non-null  int64 \n",
      " 3   education       30139 non-null  object\n",
      " 4   education.num   30139 non-null  int64 \n",
      " 5   marital.status  30139 non-null  object\n",
      " 6   occupation      30139 non-null  object\n",
      " 7   relationship    30139 non-null  object\n",
      " 8   race            30139 non-null  object\n",
      " 9   sex             30139 non-null  object\n",
      " 10  capital.gain    30139 non-null  int64 \n",
      " 11  capital.loss    30139 non-null  int64 \n",
      " 12  hours.per.week  30139 non-null  int64 \n",
      " 13  native.country  30139 non-null  object\n",
      " 14  income          30139 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# clean the data and reinspect\n",
    "data.drop_duplicates(inplace=True) # drop the duplicate rows\n",
    "data.replace('?', np.nan, inplace=True) # replace any values with a ? with \"NaN\" or \"Not a Number\"\n",
    "data.dropna(inplace=True) # drop any rows that have NA values\n",
    "data.info() # inspect data again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've dropped all duplicate rows and all rows with ? or null values, next we need to convert our variables with categorical answers to numeric values, extract our label, and scale our numeric values. For this, we'll use the classical machine learning library `sci-kit-learn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# one hot encode the categorical features\n",
    "categorical_features = ['workclass', 'education', 'marital.status', 'occupation', \n",
    "                        'relationship', 'race', 'sex', 'native.country', 'income']\n",
    "\n",
    "for feature in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    data[feature] = le.fit_transform(data[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# extract the label column\n",
    "X = data.drop('income', axis=1)\n",
    "y = data['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# scale the numeric features to each have a mean of 0, std dev of 1\n",
    "continuous_features = ['age', 'fnlwgt', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']\n",
    "scaler = StandardScaler()\n",
    "X[continuous_features] = scaler.fit_transform(X[continuous_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# split the data into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch & Tensors\n",
    "Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.\n",
    "\n",
    "Tensors are similar to NumPy’s ndarrays, except that tensors can run on GPUs or other hardware accelerators. In fact, tensors and NumPy arrays can often share the same underlying memory, eliminating the need to copy data (see Bridge with NumPy). Tensors are also optimized for automatic differentiation (we’ll see more about that later in the Autograd section). If you’re familiar with ndarrays, you’ll be right at home with the Tensor API.\n",
    "\n",
    "Learn more here: https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html\n",
    "\n",
    "To start let's import the libraries we need from PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# convert test and training data to a tensor\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets & Dataloaders\n",
    "Code for processing data samples can get messy and hard to maintain; we ideally want our dataset code to be decoupled from our model training code for better readability and modularity. PyTorch provides two data primitives: torch.utils.data.DataLoader and torch.utils.data.Dataset that allow you to use pre-loaded datasets as well as your own data. Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset to enable easy access to the samples.\n",
    "\n",
    "Learn more here: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# create a TensorDataset within Pytorch\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# wrap the Dataset in a DataLoader to be iterable\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Device for Training\n",
    "We want to be able to train our model on a hardware accelerator like the GPU or MPS, if available. Let’s check to see if torch.cuda or torch.backends.mps are available, otherwise we use the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Machine Learning Model\n",
    "\n",
    "Here's the fun part, building the machine learning model! Pytorch makes this relatively straightforward. Let's start with a very simple model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_relu_stack(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the X_train_tensor is: torch.Size([24111, 14])\n"
     ]
    }
   ],
   "source": [
    "# figure out the width of the input tensor\n",
    "print('The shape of the X_train_tensor is:', X_train_tensor.shape)\n",
    "# let's use the second value, the # of columns\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "\n",
    "# instantiate the model\n",
    "model = NeuralNetwork(input_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Neural Network\n",
    "\n",
    "First step is to define our training parameters. The three key ones are:\n",
    "1. Loss Function (https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
    "2. Learning Rate (https://www.geeksforgeeks.org/impact-of-learning-rate-on-a-model/)\n",
    "3. Optimizer (https://pytorch.org/docs/stable/optim.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# define a loss function\n",
    "criterion = nn.CrossEntropyLoss() # a go to for classication problems\n",
    "learning_rate = 0.001 # a standard starting point, use factors of 10\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate) # Adam Optimizer: https://arxiv.org/abs/1412.6980"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for the training loop. The following code will define how many times we want to loop over the training data, and then executes that loop, running the data through the model with each batch, calculating the loss, and updating the model parameters accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.4452\n",
      "Epoch [2/30], Loss: 0.3727\n",
      "Epoch [3/30], Loss: 0.3559\n",
      "Epoch [4/30], Loss: 0.3429\n",
      "Epoch [5/30], Loss: 0.3401\n",
      "Epoch [6/30], Loss: 0.3345\n",
      "Epoch [7/30], Loss: 0.3363\n",
      "Epoch [8/30], Loss: 0.3340\n",
      "Epoch [9/30], Loss: 0.3323\n",
      "Epoch [10/30], Loss: 0.3305\n",
      "Epoch [11/30], Loss: 0.3302\n",
      "Epoch [12/30], Loss: 0.3278\n",
      "Epoch [13/30], Loss: 0.3257\n",
      "Epoch [14/30], Loss: 0.3263\n",
      "Epoch [15/30], Loss: 0.3248\n",
      "Epoch [16/30], Loss: 0.3233\n",
      "Epoch [17/30], Loss: 0.3224\n",
      "Epoch [18/30], Loss: 0.3201\n",
      "Epoch [19/30], Loss: 0.3210\n",
      "Epoch [20/30], Loss: 0.3180\n",
      "Epoch [21/30], Loss: 0.3163\n",
      "Epoch [22/30], Loss: 0.3166\n",
      "Epoch [23/30], Loss: 0.3149\n",
      "Epoch [24/30], Loss: 0.3134\n",
      "Epoch [25/30], Loss: 0.3131\n",
      "Epoch [26/30], Loss: 0.3109\n",
      "Epoch [27/30], Loss: 0.3128\n",
      "Epoch [28/30], Loss: 0.3107\n",
      "Epoch [29/30], Loss: 0.3086\n",
      "Epoch [30/30], Loss: 0.3082\n"
     ]
    }
   ],
   "source": [
    "# Set the number of times to iterate over the entire training dataset\n",
    "num_epochs = 30\n",
    "\n",
    "# Start the training loop, iterating through the dataset `num_epochs` times\n",
    "for epoch in range(num_epochs):  # Loop over each epoch\n",
    "    model.train()  # Put the model into training mode (enables features like dropout)\n",
    "    running_loss = 0.0  # Initialize a variable to keep track of cumulative loss for the epoch\n",
    "\n",
    "    # Loop through each batch of data in the training dataset\n",
    "    for inputs, labels in train_loader:  # `inputs` are the features, `labels` are the targets\n",
    "        optimizer.zero_grad()  # Clear the gradients from the previous step\n",
    "        \n",
    "        outputs = model(inputs)  # Perform a forward pass through the model to get predictions\n",
    "        loss = criterion(outputs, labels)  # Compute the loss between predictions and actual labels\n",
    "        loss.backward()  # Perform backpropagation to calculate gradients of loss with respect to parameters\n",
    "        optimizer.step()  # Update model parameters based on the gradients\n",
    "        \n",
    "        running_loss += loss.item()  # Accumulate the loss for this batch\n",
    "    \n",
    "    # Calculate the average loss for this epoch\n",
    "    avg_loss = running_loss / len(train_loader)  # Divide total loss by the number of batches\n",
    "    # Print progress, showing the current epoch and average loss for the epoch\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "The code below runs the test data through our trained model, and reports on the performance. Remember, the model did not see this data in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 85.00%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Put the model in evaluation mode (disables features like dropout and gradient tracking)\n",
    "correct = 0  # Initialize a counter for correctly classified samples\n",
    "total = 0  # Initialize a counter for the total number of samples\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation for efficiency and to save memory\n",
    "    for inputs, labels in test_loader:  # Loop through each batch in the test dataset\n",
    "        outputs = model(inputs)  # Perform a forward pass through the model to get predictions\n",
    "        _, predicted = torch.max(outputs.data, 1)  # Get the class with the highest probability for each sample\n",
    "        total += labels.size(0)  # Update the total count with the number of samples in this batch\n",
    "        correct += (predicted == labels).sum().item()  # Increment the correct count for accurate predictions\n",
    "\n",
    "accuracy = 100 * correct / total  # Calculate accuracy as a percentage\n",
    "print(f'Accuracy on test data: {accuracy:.2f}%')  # Display the accuracy of the model on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving & Loading our Model\n",
    "A common way to save a model is to serialize the internal state dictionary (containing the model parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"models/income.pth\")\n",
    "print(\"Saved PyTorch Model State to models/income.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# The process for loading a model includes re-creating the model structure and loading the state dictionary into it\n",
    "model = NeuralNetwork(input_dim)\n",
    "model.load_state_dict(torch.load(\"models/income.pth\", weights_only=True))\n",
    "model = model.to(device) # move from cpu to gpu if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Over $50k\", Actual: \"Over $50k\"\n"
     ]
    }
   ],
   "source": [
    "# This model can now be used to make predictions.\n",
    "classes = [\"Over $50k\", \"Under $50k\"] # is this correct, or should it be switched?\n",
    "row_index_to_test = 2\n",
    "\n",
    "# evaluate the model on this one item from the dataset\n",
    "model.eval()\n",
    "x, y = test_dataset[row_index_to_test][0], test_dataset[row_index_to_test][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "Write your answers to the following questions in a markdown cell at the end of your notebook.\n",
    "1. Play with the MLP model. Consider adding more layers, changing the size of layers, adding things like drop out, etc. Full list of types is here: torch.nn. What model architecture worked best for you?\n",
    "2. Play with the optimization parameters. Try other learning rates, more or less epochs, different loss functions, optimizers, etc. See which one gets a good result fastest. What model parameters worked best for you?\n",
    "3. Reflect on the question, what are some ethical considerations for building a model that classifies people as high or low earners based on their demographics?\n",
    "\n",
    "## Bonus Challenge #1\n",
    "Compare the performance of your neural network to some classical machine learning methods. Does this dataset / problem merit \"deep\" learning? Why or why not?\n",
    "\n",
    "## Bonus Challenge #2\n",
    "Feature importance: query your best neural network to see which features were the best predictors of income. Which ones were the best predictors?\n",
    "\n",
    "## Bonus Challenge #3\n",
    "Modify your trained network to predict salary as a regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Notebook to HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook income-mlp.ipynb to html\n",
      "[NbConvertApp] Writing 334120 bytes to income-mlp.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# export to HTML for webpage\n",
    "import os\n",
    "os.system('jupyter nbconvert --to html income-mlp.ipynb --HTMLExporter.theme=dark')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4979622,
     "sourceId": 8375157,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
