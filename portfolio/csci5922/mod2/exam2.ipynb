{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 5922 Exam 2\n",
    "October 24, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2:\n",
    "```{math}\n",
    "x =  [  [ 1   2   3] \n",
    "        [ 2   4   1]\n",
    "        [ 4   3   2] ]\n",
    "\n",
    "y = [0\n",
    "    0\n",
    "    1]\n",
    "\n",
    "Assuming X is actually 3D\n",
    "\n",
    "W1=[ [1, 1, 1]\n",
    "    [1, 1, 1]\n",
    "    [1, 1, 1] ]\n",
    "\n",
    "W2 = [[1]\n",
    "      [1]\n",
    "      [1]]  \n",
    "\n",
    "b = 0\n",
    "\n",
    "\n",
    "Z1 = x*W1t + b\n",
    "Z1 =  [  [ 1   2   3] \n",
    "        [ 2   4   1]\n",
    "        [ 4   3   2] ]\n",
    "*\n",
    "    [[1, 1, 1]\n",
    "    [1, 1, 1]\n",
    "    [1, 1, 1] ]\n",
    "+ 0\n",
    "\n",
    "Z1=[[ 6 6 6]\n",
    "    [ 7 7 7]\n",
    "    [ 9 9 9]]\n",
    "\n",
    "H1 = ReLU(Z1)\n",
    "H1 = [[ 6 6 6]\n",
    "    [ 7 7 7]\n",
    "    [ 9 9 9]]\n",
    "\n",
    "Z2 = H1*W2 + b\n",
    "Z2 = [[ 6 6 6]\n",
    "    [ 7 7 7]\n",
    "    [ 9 9 9]]\n",
    "    *\n",
    "    [[1]\n",
    "    [1]\n",
    "    [1]]\n",
    "    + 0\n",
    "Z2 = [[18]\n",
    "    [21]\n",
    "    [27]]\n",
    "\n",
    "Y^ = sigmoid(Z2)\n",
    "Y^=[[0.9999999]\n",
    "    [0.9999999]\n",
    "    [0.9999999]]\n",
    "Approximate 0.9999999 as 1\n",
    "Y^=[[1]\n",
    "    [1]\n",
    "    [1]]\n",
    "\n",
    "L = -y*log(y^) - (1-y)*log(1-y^)\n",
    "L=[[18]\n",
    "    [0]\n",
    "    [0]]\n",
    "\n",
    "dL/dW1 = dL/dy^ * dy^/dZ2 * dZ2/dH1 * dH1/dZ1 * dZ1/dW1\n",
    "\n",
    "dL/dy^ = -y/y^ - (1-y)/(1-y^)\n",
    "dy^/dZ2 = y^*(1-y^)\n",
    "dZ2/dH1 = W2\n",
    "dH1/dZ1 = 1 if Z1>0 else 0\n",
    "dZ1/dW1 = x\n",
    "\n",
    "dL/dy^ = [[-1]\n",
    "        [0]\n",
    "        [0]]\n",
    "\n",
    "        *** COME BACK AND CALCULATE dL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2a-c: Create and read in dataa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.set_printoptions(precision=6)\n",
    "\n",
    "def get_xy(df):\n",
    "   \n",
    "    nrows = df.shape[0]\n",
    "    ncols = df.shape[1]\n",
    "   \n",
    "    x = np.empty((nrows,ncols-1))\n",
    "    y = np.empty((nrows,1))\n",
    "\n",
    "    # separate labels\n",
    "    if 'LABEL' in df.columns:\n",
    "        y = np.array(df['LABEL'])\n",
    "        x = np.array(df[df.columns.difference(['LABEL'])])\n",
    "    elif 'label' in df.columns:\n",
    "        y = np.array(df['label'])\n",
    "        x = np.array(df[df.columns.difference(['label'])])\n",
    "    else:\n",
    "        raise Exception('There is no column with the title label in the data')\n",
    "    return x, y\n",
    "\n",
    "def binary_labels(y):\n",
    "    y_values = set(y)\n",
    "    y_value_0 = list(y_values)[0]\n",
    "    y_value_1 = list(y_values)[1]\n",
    "    y[y == y_value_0] = 0\n",
    "    y[y == y_value_1] = 1\n",
    "    y = y.reshape(-1, 1)\n",
    "    return y.astype(int)\n",
    "\n",
    "def normalize(x):\n",
    "    xrows = x.shape[0]\n",
    "    xcols = x.shape[1]\n",
    "    xnorm = np.empty((xrows, xcols))\n",
    "    for j, column in enumerate(x.T):\n",
    "        max = column.max()\n",
    "        min = column.min()\n",
    "        for i, item in enumerate(column):\n",
    "            xnorm[i,j] = (item - min)/(max - min)\n",
    "    return xnorm.astype(float)\n",
    "\n",
    "\n",
    "# create a function to one-hot-encode categorical data\n",
    "def one_hot_encode(y):\n",
    "    y_values = set(y)\n",
    "    y_length = len(y_values)\n",
    "    # convert values in y to integers\n",
    "    for i, item in enumerate(y_values):\n",
    "        y[y == item] = i\n",
    "\n",
    "    # create new y array with one hot encoding\n",
    "    y_new = np.zeros((len(y), y_length))\n",
    "    for i, item in enumerate(y): \n",
    "        y_new[i, item] = 1    \n",
    "    return y_new.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data is: \n",
      "    experience  skill  athleticism  label\n",
      "0           5      8            5      2\n",
      "1           4      4            3      2\n",
      "2           4      8            5      1\n",
      "3           1      2            1      1\n",
      "4           0      2            0      0\n",
      "5           0      0            1      0\n",
      "\n",
      "X is: \n",
      " [[5 5 8]\n",
      " [3 4 4]\n",
      " [5 4 8]\n",
      " [1 1 2]\n",
      " [0 0 2]\n",
      " [1 0 0]]\n",
      "\n",
      "Y one hot encoded is: \n",
      " [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df2 = pd.read_csv('A2_Exam_ILG.csv')\n",
    "x2, y2 = get_xy(df2)\n",
    "# x2 = normalize(x2)\n",
    "y2 = one_hot_encode(y2)\n",
    "\n",
    "print('The data is: \\n', df2)\n",
    "print('\\nX is: \\n', x2)\n",
    "print('\\nY one hot encoded is: \\n', y2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is:   \n",
    "    experience  skill  athleticism  label  \n",
    "0           5      8            5      2  \n",
    "1           4      4            3      2  \n",
    "2           4      8            5      1  \n",
    "3           1      2            1      1  \n",
    "4           0      2            0      0  \n",
    "5           0      0            1      0  \n",
    "  \n",
    "X is:   \n",
    " [[5 5 8]  \n",
    " [3 4 4]  \n",
    " [5 4 8]  \n",
    " [1 1 2]  \n",
    " [0 0 2]  \n",
    " [1 0 0]]  \n",
    "  \n",
    "Y one hot encoded is:   \n",
    " [[0 0 1]  \n",
    " [0 0 1]  \n",
    " [0 1 0]  \n",
    " [0 1 0]  \n",
    " [1 0 0]  \n",
    " [1 0 0]]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "\n",
    "# activation function 1\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    return sigmoid(z) * (1-sigmoid(z))\n",
    "\n",
    "# activation function 2\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "def relu_derivative(z):\n",
    "    return np.where(z > 0, 1, 0)\n",
    "\n",
    "# loss function\n",
    "def cce(y, y_hat):\n",
    "    return -np.sum(y*np.log(y_hat))\n",
    "\n",
    "# output layer activation function\n",
    "def softmax(z):\n",
    "    return np.exp(z)/np.sum(np.exp(z), axis=1).reshape(-1, 1)\n",
    "\n",
    "\n",
    "#2: Code the feedforward function\n",
    "class NeuralNetworkCCE():\n",
    "    # assumes one hidden layer\n",
    "    # assumes one-hot-encoded y\n",
    "    # assumes softmax activation on output layer\n",
    "    # assumes cross-entropy loss\n",
    "\n",
    "    def __init__(self, LR=0.1, epochs=10, activation='relu', input_layer_dim=3, hidden_layer_dim=2, output_layer_dim=4):\n",
    "        self.LR = LR\n",
    "        self.epochs = epochs\n",
    "        # shape parameters\n",
    "        self.hidden_layer_dim = hidden_layer_dim\n",
    "        self.output_layer_dim = output_layer_dim\n",
    "        self.input_layer_dim = input_layer_dim\n",
    "\n",
    "        if activation == 'relu':\n",
    "            self.activation = relu\n",
    "            self.activation_derivative = relu_derivative\n",
    "        elif activation == 'sigmoid': \n",
    "            self.activation = sigmoid\n",
    "            self.activation_derivative = sigmoid_derivative\n",
    "        \n",
    "        if output_layer_dim == 1:\n",
    "            self.output_activation = sigmoid\n",
    "        else:\n",
    "            self.output_activation = softmax\n",
    "\n",
    "        # initialize with weights as ones and biases as zeros\n",
    "        self.w1 = np.ones((self.hidden_layer_dim, self.input_layer_dim))\n",
    "        self.b = np.zeros((1, self.hidden_layer_dim))\n",
    "        self.w2 = np.ones((self.output_layer_dim, self.hidden_layer_dim))\n",
    "        self.c = np.zeros((1, self.output_layer_dim))\n",
    "    \n",
    "    def randomize_weights(self):\n",
    "        np.random.seed(44)\n",
    "        self.w1 = np.random.rand(self.hidden_layer_dim, self.input_layer_dim)\n",
    "        self.b = np.random.rand(1, self.hidden_layer_dim)\n",
    "        self.w2 = np.random.rand(self.output_layer_dim, self.hidden_layer_dim)\n",
    "        self.c = np.random.rand(1, self.output_layer_dim)\n",
    "\n",
    "    def feed_forward(self, x):\n",
    "        self.z1 = (x @ self.w1.T + self.b).astype(float)\n",
    "        self.h = self.activation(self.z1).astype(float)\n",
    "        self.z2 = (self.h @ self.w2.T + self.c).astype(float)\n",
    "        self.y_hat = self.output_activation(self.z2).astype(float)\n",
    "        self.output = np.argmax(self.y_hat, axis=1).reshape(-1, 1)\n",
    "        return\n",
    "   \n",
    "    def calculate_loss(self, y):\n",
    "        self.loss = cce(y, self.y_hat).astype(float)\n",
    "        return\n",
    "    \n",
    "    def print_params(self, y):\n",
    "        print('\\nW1 is: \\n', self.w1.T) # shape is (2x3)\n",
    "        print('\\nB is: \\n', self.b) # shape is (1x2)\n",
    "        print('\\nZ1 is: \\n', self.z1) # shape is (17x2)\n",
    "        print('\\nH is: \\n', self.h) # shape is (17x2)\n",
    "        print('\\nW2 is: \\n', self.w2.T) # shape is (4x2)\n",
    "        print('\\nZ2 is: \\n', self.z2) # shape is (17x4)\n",
    "        print('\\nC is: \\n', self.c) # shape is (1x4)\n",
    "        print('\\ny^ is: \\n', self.y_hat) # shape is (17x4)\n",
    "        print('\\ny^-y is: \\n', self.y_hat - y) # shape is (17x4)\n",
    "        print('\\noutput is: \\n', self.output) # shape is (17x1)\n",
    "        print('\\nL is: \\n', self.loss) # shape is (1x1)\n",
    "        \n",
    "\n",
    "    def backpropogate(self, x, y):\n",
    "        self.dLdC = (self.y_hat - y).astype(float) # shape is (17x4) \n",
    "        self.dLdW2 = (self.dLdC.T @ self.h).astype(float) # (4x17)*(17x2) = (4x2)\n",
    "        self.dLdB = (self.dLdC @ self.w2 * self.activation_derivative(self.z1)).astype(float) # (17x4) @ (4x2) * (17x2) = (17x2)\n",
    "        self.dLdW1 = (self.dLdB.T @ x).astype(float) # (2x17)*(17x3) = (2x3)\n",
    "    \n",
    "    def print_derivatives(self):\n",
    "        print('\\ndLdC is: \\n', self.dLdC) # shape is (17x4)\n",
    "        print('\\ndLdW2 is: \\n', self.dLdW2) # shape is (4x2)\n",
    "        print('\\ndLdB is: \\n', self.dLdB) # shape is (17x2)\n",
    "        print('\\ndLdW1 is \\n', self.dLdW1) # shape is (2x3)\n",
    "\n",
    "    def print_new_params(self):\n",
    "        print('\\nNew W1 is: \\n', self.w1.T)\n",
    "        print('\\nNew B is: \\n', self.b)\n",
    "        print('\\nNew W2 is: \\n', self.w2.T)\n",
    "        print('\\nNew C is: \\n', self.c)\n",
    "\n",
    "    def update_params(self):\n",
    "        self.c = (self.c - self.LR * self.dLdC.mean(axis=0)).astype(float) # (1x4)-LR*(17x4).mean = (1x4)\n",
    "        self.w2 = (self.w2 - self.LR * self.dLdW2).astype(float) # (4x2)-LR*(4x2).mean = (4x2) \n",
    "        self.b = (self.b - self.LR * self.dLdB.mean(axis=0)).astype(float) # (1x2)-LR*(17x2).mean = (1x2)\n",
    "        self.w1 = (self.w1 - self.LR * self.dLdW1).astype(float) # (2x3)-LR*(2x3) = (2x3)\n",
    "        return\n",
    "\n",
    "    def train(self, x, y, verbose=False, plot=True):\n",
    "        if verbose:\n",
    "            print('Preparing to train Neural Network...')\n",
    "            print('X is: \\n', x)\n",
    "            print('\\ny is: \\n', y)\n",
    "        self.randomize_weights()\n",
    "        self.loss_by_epoch = []\n",
    "        for e in range(self.epochs):\n",
    "            if verbose:\n",
    "                print('###############################################################\\nNow running epoch', e+1, 'of', self.epochs, 'total epochs.')\n",
    "                print('Feeding forward...')\n",
    "            self.feed_forward(x)\n",
    "            if verbose:\n",
    "                print('Calculating loss...')\n",
    "            self.calculate_loss(y)\n",
    "            if verbose:\n",
    "                print('The parameters are: ')\n",
    "                self.print_params(y)\n",
    "                print('\\nPerforming backpropogation...')\n",
    "            self.backpropogate(x, y)\n",
    "            self.update_params()\n",
    "            if verbose:\n",
    "                print('The derivatives are: ')\n",
    "                self.print_derivatives()\n",
    "                self.print_new_params()\n",
    "                print('\\nFinished epoch', e+1, 'with loss', self.loss)\n",
    "            self.loss_by_epoch.append(self.loss)\n",
    "        if verbose:\n",
    "            print('Training complete! Loss by epoch is: \\n', self.loss_by_epoch)\n",
    "        if plot:\n",
    "            y = self.loss_by_epoch\n",
    "            x = range(self.epochs)\n",
    "            plt.plot(x, y)\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title('Loss by Epoch')\n",
    "            plt.show()\n",
    "\n",
    "    # multilabel confusion matrix\n",
    "    def plot_confusion_matrix(self, y):\n",
    "        y_pred = self.output\n",
    "        y = np.argmax(self.y_hat, axis=1).reshape(-1, 1)\n",
    "        self.cm = confusion_matrix(y, y_pred)\n",
    "        classes = ['0: Bad', '1: Okay', '2: Good', '3: Great']\n",
    "        display = ConfusionMatrixDisplay(self.cm, display_labels=classes)\n",
    "        display.ax_.set_title('Confusion Matrix for Player Ability Prediction')\n",
    "        display.plot()\n",
    "        # calculate accuracy\n",
    "        self.accuracy = accuracy_score(y, y_pred)\n",
    "        print('Accuracy is: ', self.accuracy)\n",
    "    \n",
    "    def predict(self, x, y):\n",
    "        self.feed_forward(x)\n",
    "        self.plot_confusion_matrix(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to train Neural Network...\n",
      "X is: \n",
      " [[5 5 8]\n",
      " [3 4 4]\n",
      " [5 4 8]\n",
      " [1 1 2]\n",
      " [0 0 2]\n",
      " [1 0 0]]\n",
      "\n",
      "y is: \n",
      " [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]]\n",
      "###############################################################\n",
      "Now running epoch 1 of 1 total epochs.\n",
      "Feeding forward...\n",
      "Calculating loss...\n",
      "The parameters are: \n",
      "\n",
      "W1 is: \n",
      " [[0.834842 0.360501]\n",
      " [0.104796 0.359311]\n",
      " [0.74464  0.609238]]\n",
      "\n",
      "B is: \n",
      " [[0.39378  0.409073]]\n",
      "\n",
      "Z1 is: \n",
      " [[11.049095  8.882038]\n",
      " [ 6.296052  5.364772]\n",
      " [10.944299  8.522727]\n",
      " [ 2.822699  2.347361]\n",
      " [ 1.883061  1.627549]\n",
      " [ 1.228622  0.769573]]\n",
      "\n",
      "H is: \n",
      " [[0.999984 0.999861]\n",
      " [0.99816  0.995343]\n",
      " [0.999982 0.999801]\n",
      " [0.94389  0.912724]\n",
      " [0.867962 0.835834]\n",
      " [0.773577 0.683429]]\n",
      "\n",
      "W2 is: \n",
      " [[0.509902 0.960526 0.427652]\n",
      " [0.710148 0.456621 0.113464]]\n",
      "\n",
      "Z2 is: \n",
      " [[1.437843 2.374541 1.484443]\n",
      " [1.433704 2.370726 1.483151]\n",
      " [1.437799 2.374512 1.484436]\n",
      " [1.34736  2.280872 1.450568]\n",
      " [1.254041 2.172832 1.409373]\n",
      " [1.097683 2.012581 1.351717]]\n",
      "\n",
      "C is: \n",
      " [[0.217899 0.957472 0.943351]]\n",
      "\n",
      "y^ is: \n",
      " [[0.217427 0.554774 0.227799]\n",
      " [0.217247 0.554494 0.228259]\n",
      " [0.217423 0.554773 0.227803]\n",
      " [0.214954 0.546721 0.238325]\n",
      " [0.213936 0.536178 0.249887]\n",
      " [0.208954 0.521659 0.269387]]\n",
      "\n",
      "y^-y is: \n",
      " [[ 0.217427  0.554774 -0.772201]\n",
      " [ 0.217247  0.554494 -0.771741]\n",
      " [ 0.217423 -0.445227  0.227803]\n",
      " [ 0.214954 -0.453279  0.238325]\n",
      " [-0.786064  0.536178  0.249887]\n",
      " [-0.791046  0.521659  0.269387]]\n",
      "\n",
      "output is: \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "\n",
      "L is: \n",
      " 7.2572989286716245\n",
      "\n",
      "Performing backpropogation...\n",
      "The derivatives are: \n",
      "\n",
      "dLdC is: \n",
      " [[ 0.217427  0.554774 -0.772201]\n",
      " [ 0.217247  0.554494 -0.771741]\n",
      " [ 0.217423 -0.445227  0.227803]\n",
      " [ 0.214954 -0.453279  0.238325]\n",
      " [-0.786064  0.536178  0.249887]\n",
      " [-0.791046  0.521659  0.269387]]\n",
      "\n",
      "dLdW2 is: \n",
      " [[-0.439626 -0.350436]\n",
      " [ 1.1041    1.052424]\n",
      " [-0.664474 -0.701988]]\n",
      "\n",
      "dLdB is: \n",
      " [[ 4.985111e-06  4.443842e-05]\n",
      " [ 5.755481e-04  1.482784e-03]\n",
      " [-3.873533e-06 -4.582692e-06]\n",
      " [-1.185601e-02 -2.173579e-03]\n",
      " [ 2.533444e-02 -3.911183e-02]\n",
      " [ 3.729315e-02 -6.339030e-02]]\n",
      "\n",
      "dLdW1 is \n",
      " [[ 0.027169 -0.009544  0.029268]\n",
      " [-0.060916  0.003961 -0.076321]]\n",
      "\n",
      "New W1 is: \n",
      " [[0.807673 0.421417]\n",
      " [0.11434  0.355349]\n",
      " [0.715373 0.685559]]\n",
      "\n",
      "New B is: \n",
      " [[0.385222 0.426265]]\n",
      "\n",
      "New W2 is: \n",
      " [[ 0.949528 -0.143574  1.092126]\n",
      " [ 1.060584 -0.595803  0.815451]]\n",
      "\n",
      "New C is: \n",
      " [[0.336242 0.746039 1.036441]]\n",
      "\n",
      "Finished epoch 1 with loss 7.2572989286716245\n",
      "Training complete! Loss by epoch is: \n",
      " [7.2572989286716245]\n"
     ]
    }
   ],
   "source": [
    "# test code with verbose mode\n",
    "nn1 = NeuralNetworkCCE(\n",
    "    LR=1,\n",
    "    epochs=1, \n",
    "    activation='sigmoid', \n",
    "    input_layer_dim=3, \n",
    "    hidden_layer_dim=2, \n",
    "    output_layer_dim=3\n",
    ")\n",
    "nn1.train(x2, y2, verbose=True, plot=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W1 is:   \n",
    " [[0.834842 0.360501]  \n",
    " [0.104796 0.359311]  \n",
    " [0.74464  0.609238]]  \n",
    "  \n",
    "W2 is:   \n",
    " [[0.509902 0.960526 0.427652]  \n",
    " [0.710148 0.456621 0.113464]]  \n",
    "  \n",
    "B is:   \n",
    " [[0.39378  0.409073]]  \n",
    "  \n",
    "   \n",
    "C is:   \n",
    " [[0.217899 0.957472 0.943351]]  \n",
    "  \n",
    "Z1 is:   \n",
    " [[11.049095  8.882038]  \n",
    " [ 6.296052  5.364772]  \n",
    " [10.944299  8.522727]  \n",
    " [ 2.822699  2.347361]  \n",
    " [ 1.883061  1.627549]  \n",
    " [ 1.228622  0.769573]]  \n",
    "  \n",
    "H is:   \n",
    " [[0.999984 0.999861]  \n",
    " [0.99816  0.995343]  \n",
    " [0.999982 0.999801]  \n",
    " [0.94389  0.912724]  \n",
    " [0.867962 0.835834]  \n",
    " [0.773577 0.683429]]  \n",
    "  \n",
    "Z2 is:   \n",
    " [[1.437843 2.374541 1.484443]  \n",
    " [1.433704 2.370726 1.483151]  \n",
    " [1.437799 2.374512 1.484436]  \n",
    " [1.34736  2.280872 1.450568]  \n",
    " [1.254041 2.172832 1.409373]  \n",
    " [1.097683 2.012581 1.351717]]  \n",
    "  \n",
    "  \n",
    "y^ is:   \n",
    " [[0.217427 0.554774 0.227799]  \n",
    " [0.217247 0.554494 0.228259]  \n",
    " [0.217423 0.554773 0.227803]  \n",
    " [0.214954 0.546721 0.238325]  \n",
    " [0.213936 0.536178 0.249887]  \n",
    " [0.208954 0.521659 0.269387]]  \n",
    "  \n",
    "y^-y is:   \n",
    " [[ 0.217427  0.554774 -0.772201]  \n",
    " [ 0.217247  0.554494 -0.771741]  \n",
    " [ 0.217423 -0.445227  0.227803]  \n",
    " [ 0.214954 -0.453279  0.238325]  \n",
    " [-0.786064  0.536178  0.249887]  \n",
    " [-0.791046  0.521659  0.269387]]  \n",
    "  \n",
    "dLdC is:   \n",
    " [[ 0.217427  0.554774 -0.772201]  \n",
    " [ 0.217247  0.554494 -0.771741]  \n",
    " [ 0.217423 -0.445227  0.227803]  \n",
    " [ 0.214954 -0.453279  0.238325]  \n",
    " [-0.786064  0.536178  0.249887]  \n",
    " [-0.791046  0.521659  0.269387]]  \n",
    "  \n",
    "dLdW2 is:   \n",
    " [[-0.439626 -0.350436]  \n",
    " [ 1.1041    1.052424]  \n",
    " [-0.664474 -0.701988]]  \n",
    "  \n",
    "dLdB is:   \n",
    " [[ 4.985111e-06  4.443842e-05]  \n",
    " [ 5.755481e-04  1.482784e-03]  \n",
    " [-3.873533e-06 -4.582692e-06]  \n",
    " [-1.185601e-02 -2.173579e-03]  \n",
    " [ 2.533444e-02 -3.911183e-02]  \n",
    " [ 3.729315e-02 -6.339030e-02]]  \n",
    "  \n",
    "dLdW1 is   \n",
    " [[ 0.027169 -0.009544  0.029268]  \n",
    " [-0.060916  0.003961 -0.076321]]  \n",
    "  \n",
    "Average Loss is:   \n",
    " 7.2572989286716245  \n",
    "  \n",
    "New W1 is:   \n",
    " [[0.807673 0.421417]  \n",
    " [0.11434  0.355349]  \n",
    " [0.715373 0.685559]]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data is: \n",
      "    x1  x2  x3  label\n",
      "0   1   2   3      0\n",
      "1   2   4   1      1\n",
      "2   4   3   2      1\n",
      "\n",
      "X is: \n",
      " [[1 2 3]\n",
      " [2 4 1]\n",
      " [4 3 2]]\n",
      "\n",
      "Y is: \n",
      " [0 1 1]\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.read_csv('A2_Exam2_ILG.csv')\n",
    "x3, y3 = get_xy(df3)\n",
    "# x3 = normalize(x3)\n",
    "# y3 = one_hot_encode(y3)\n",
    "\n",
    "print('The data is: \\n', df3)\n",
    "print('\\nX is: \\n', x3)\n",
    "print('\\nY is: \\n', y3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to train Neural Network...\n",
      "X is: \n",
      " [[1 2 3]\n",
      " [2 4 1]\n",
      " [4 3 2]]\n",
      "\n",
      "y is: \n",
      " [0 1 1]\n",
      "###############################################################\n",
      "Now running epoch 1 of 1 total epochs.\n",
      "Feeding forward...\n",
      "Calculating loss...\n",
      "The parameters are: \n",
      "\n",
      "W1 is: \n",
      " [[0.834842 0.360501 0.39378 ]\n",
      " [0.104796 0.359311 0.409073]\n",
      " [0.74464  0.609238 0.509902]]\n",
      "\n",
      "B is: \n",
      " [[0.710148 0.960526 0.456621]]\n",
      "\n",
      "Z1 is: \n",
      " [[3.988504 3.867364 3.198253]\n",
      " [3.543657 3.72801  3.390373]\n",
      " [5.853186 4.698939 4.278762]]\n",
      "\n",
      "H is: \n",
      " [[0.98181  0.979515 0.960768]\n",
      " [0.971905 0.976524 0.967402]\n",
      " [0.997137 0.990977 0.98633 ]]\n",
      "\n",
      "W2 is: \n",
      " [[0.427652]\n",
      " [0.113464]\n",
      " [0.217899]]\n",
      "\n",
      "Z2 is: \n",
      " [[1.697834]\n",
      " [1.694704]\n",
      " [1.711259]]\n",
      "\n",
      "C is: \n",
      " [[0.957472]]\n",
      "\n",
      "y^ is: \n",
      " [[1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "\n",
      "y^-y is: \n",
      " [[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "\n",
      "output is: \n",
      " [[0]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "L is: \n",
      " -0.0\n",
      "\n",
      "Performing backpropogation...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9832\\2805354133.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0moutput_layer_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m )\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mnn2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9832\\171258732.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x, y, verbose, plot)\u001b[0m\n\u001b[0;32m    131\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nPerforming backpropogation...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackpropogate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9832\\171258732.py\u001b[0m in \u001b[0;36mbackpropogate\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdLdC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_hat\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# shape is (17x4)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdLdW2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdLdC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# (4x17)*(17x2) = (4x2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdLdB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdLdC\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation_derivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# (17x4) @ (4x2) * (17x2) = (17x2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdLdW1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdLdB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# (2x17)*(17x3) = (2x3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 3)"
     ]
    }
   ],
   "source": [
    "# test code with verbose mode\n",
    "nn2 = NeuralNetworkCCE(\n",
    "    LR=1,\n",
    "    epochs=1, \n",
    "    activation='sigmoid', \n",
    "    input_layer_dim=3, \n",
    "    hidden_layer_dim=3, \n",
    "    output_layer_dim=1\n",
    ")\n",
    "nn2.train(x3, y3, verbose=True, plot=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
